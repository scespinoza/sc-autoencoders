{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from preprocess import GSE\n",
    "from models import AutoEncoder, VariationalAutoEncoder, VariationalDeepEmbedding, PlotLatentSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GSE()\n",
    "X_train, y_train = dataset.train\n",
    "X_test, y_test = dataset.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VariationalDeepEmbedding(original_dim=dataset.n_genes, pretrain=True, n_components=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 322 samples\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['AutoEncoder/Encoder/dense_3/kernel:0', 'AutoEncoder/Encoder/dense_3/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['AutoEncoder/Encoder/dense_3/kernel:0', 'AutoEncoder/Encoder/dense_3/bias:0'] when minimizing the loss.\n",
      "322/322 [==============================] - 10s 33ms/sample - loss: 3970.8794\n",
      "Epoch 2/30\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3590.9870\n",
      "Epoch 3/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3518.5352\n",
      "Epoch 4/30\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3491.5314\n",
      "Epoch 5/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3485.5280\n",
      "Epoch 6/30\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3478.8293\n",
      "Epoch 7/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3469.2995\n",
      "Epoch 8/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3455.6841\n",
      "Epoch 9/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3440.8761\n",
      "Epoch 10/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3434.0173\n",
      "Epoch 11/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3427.6872\n",
      "Epoch 12/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3423.2211\n",
      "Epoch 13/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3419.6417\n",
      "Epoch 14/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3420.2812\n",
      "Epoch 15/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3418.2314\n",
      "Epoch 16/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3414.8769\n",
      "Epoch 17/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3412.5289\n",
      "Epoch 18/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3408.6523\n",
      "Epoch 19/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3406.7093\n",
      "Epoch 20/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3403.1728\n",
      "Epoch 21/30\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3398.9179\n",
      "Epoch 22/30\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3397.9674\n",
      "Epoch 23/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3391.5582\n",
      "Epoch 24/30\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3385.4686\n",
      "Epoch 25/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3380.6137\n",
      "Epoch 26/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3375.2160\n",
      "Epoch 27/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3370.3283\n",
      "Epoch 28/30\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3364.2621\n",
      "Epoch 29/30\n",
      "322/322 [==============================] - 5s 15ms/sample - loss: 3358.7107\n",
      "Epoch 30/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3356.4339\n",
      "Fitting GMM\n",
      "WARNING:tensorflow:Layer Encoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Train on 322 samples\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['AutoEncoder/Encoder/dense_3/kernel:0', 'AutoEncoder/Encoder/dense_3/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['AutoEncoder/Encoder/dense_3/kernel:0', 'AutoEncoder/Encoder/dense_3/bias:0'] when minimizing the loss.\n",
      "322/322 [==============================] - 9s 29ms/sample - loss: 3364.7273\n",
      "Epoch 2/30\n",
      "322/322 [==============================] - 5s 15ms/sample - loss: 3349.1407\n",
      "Epoch 3/30\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3345.0582\n",
      "Epoch 4/30\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3341.8964\n",
      "Epoch 5/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3337.4741\n",
      "Epoch 6/30\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3335.3918\n",
      "Epoch 7/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3333.8393\n",
      "Epoch 8/30\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3330.4481\n",
      "Epoch 9/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3327.1089\n",
      "Epoch 10/30\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3326.0120\n",
      "Epoch 11/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3323.0357\n",
      "Epoch 12/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3321.7816\n",
      "Epoch 13/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3317.9557\n",
      "Epoch 14/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3314.8237\n",
      "Epoch 15/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3311.4125\n",
      "Epoch 16/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3309.3209\n",
      "Epoch 17/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3304.8590\n",
      "Epoch 18/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3301.2415\n",
      "Epoch 19/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3297.6969\n",
      "Epoch 20/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3294.5430\n",
      "Epoch 21/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3293.7114\n",
      "Epoch 22/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3290.3996\n",
      "Epoch 23/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3288.2997\n",
      "Epoch 24/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3285.3023\n",
      "Epoch 25/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3281.2685\n",
      "Epoch 26/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3279.1609\n",
      "Epoch 27/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3276.9332\n",
      "Epoch 28/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3273.6341\n",
      "Epoch 29/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3270.1868\n",
      "Epoch 30/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3267.6408\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n    relative to /home/alumnos/secancino:\n\n    single-cell-rna-seq/models.py:133 call  *\n        kl_loss = self.vade_loss([mu, logvar, z])\n    single-cell-rna-seq/models.py:161 vade_loss  *\n        return loss / tf.shape(z)[0]\n    anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py:899 binary_op_wrapper\n        return func(x, y, name=name)\n    anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py:997 _truediv_python3\n        (x_dtype, y_dtype))\n\n    TypeError: x and y must have the same dtype, got tf.float32 != tf.int32\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-03c9374d42f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruction_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m history = model.fit(X_train, X_train, epochs=1000, validation_data=(X_test, X_test),\n\u001b[0;32m----> 8\u001b[0;31m                    callbacks=[early_stopping, plot_latent], verbose=True)\n\u001b[0m",
      "\u001b[0;32m~/single-cell-rna-seq/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/single-cell-rna-seq/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariationalDeepEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting GMM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2620\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m       \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2622\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2623\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dict_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2707\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2709\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2710\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2711\u001b[0m         \u001b[0;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    841\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in converted code:\n    relative to /home/alumnos/secancino:\n\n    single-cell-rna-seq/models.py:133 call  *\n        kl_loss = self.vade_loss([mu, logvar, z])\n    single-cell-rna-seq/models.py:161 vade_loss  *\n        return loss / tf.shape(z)[0]\n    anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py:899 binary_op_wrapper\n        return func(x, y, name=name)\n    anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py:997 _truediv_python3\n        (x_dtype, y_dtype))\n\n    TypeError: x and y must have the same dtype, got tf.float32 != tf.int32\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=20)\n",
    "plot_latent = PlotLatentSpace(model, X_train, y_train, interval=10)\n",
    "model.compile(optimizer=Adam(0.0001), loss=model.reconstruction_loss)\n",
    "history = model.fit(X_train, X_train, epochs=1000, validation_data=(X_test, X_test),\n",
    "                   callbacks=[early_stopping, plot_latent], verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
