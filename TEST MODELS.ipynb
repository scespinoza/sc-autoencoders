{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from preprocess import GSE\n",
    "from models import AutoEncoder, VariationalAutoEncoder, VariationalDeepEmbedding, PlotLatentSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GSE()\n",
    "X_train, y_train = dataset.train\n",
    "X_test, y_test = dataset.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VariationalDeepEmbedding(original_dim=dataset.n_genes, pretrain=True, n_components=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 322 samples\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['AutoEncoder/Encoder/dense_3/kernel:0', 'AutoEncoder/Encoder/dense_3/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['AutoEncoder/Encoder/dense_3/kernel:0', 'AutoEncoder/Encoder/dense_3/bias:0'] when minimizing the loss.\n",
      "322/322 [==============================] - 5s 17ms/sample - loss: 3959.4586\n",
      "Epoch 2/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3582.4412\n",
      "Epoch 3/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3520.2442\n",
      "Epoch 4/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3493.9722\n",
      "Epoch 5/30\n",
      "322/322 [==============================] - 3s 9ms/sample - loss: 3486.0417\n",
      "Epoch 6/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3481.0900\n",
      "Epoch 7/30\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3477.7390\n",
      "Epoch 8/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3469.3003\n",
      "Epoch 9/30\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3456.5178\n",
      "Epoch 10/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3442.6138\n",
      "Epoch 11/30\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3435.0584\n",
      "Epoch 12/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3430.5172\n",
      "Epoch 13/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3426.8204\n",
      "Epoch 14/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3425.3499\n",
      "Epoch 15/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3420.2107\n",
      "Epoch 16/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3414.8953\n",
      "Epoch 17/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3409.6827\n",
      "Epoch 18/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3404.7500\n",
      "Epoch 19/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3398.7668\n",
      "Epoch 20/30\n",
      "322/322 [==============================] - 3s 9ms/sample - loss: 3394.3130\n",
      "Epoch 21/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3386.4138\n",
      "Epoch 22/30\n",
      "322/322 [==============================] - 3s 9ms/sample - loss: 3382.0461\n",
      "Epoch 23/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3378.6777\n",
      "Epoch 24/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3374.7186\n",
      "Epoch 25/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3371.6658\n",
      "Epoch 26/30\n",
      "322/322 [==============================] - 3s 9ms/sample - loss: 3368.9866\n",
      "Epoch 27/30\n",
      "322/322 [==============================] - 3s 8ms/sample - loss: 3364.7281\n",
      "Epoch 28/30\n",
      "322/322 [==============================] - 2s 8ms/sample - loss: 3360.4637\n",
      "Epoch 29/30\n",
      "322/322 [==============================] - 3s 8ms/sample - loss: 3359.6837\n",
      "Epoch 30/30\n",
      "322/322 [==============================] - 3s 8ms/sample - loss: 3355.6690\n",
      "Fitting GMM\n",
      "WARNING:tensorflow:Layer Encoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Train on 322 samples\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['AutoEncoder/Encoder/dense_3/kernel:0', 'AutoEncoder/Encoder/dense_3/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['AutoEncoder/Encoder/dense_3/kernel:0', 'AutoEncoder/Encoder/dense_3/bias:0'] when minimizing the loss.\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3376.0508\n",
      "Epoch 2/30\n",
      "322/322 [==============================] - 2s 7ms/sample - loss: 3354.3976\n",
      "Epoch 3/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3348.8375\n",
      "Epoch 4/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3345.1572\n",
      "Epoch 5/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3342.9923\n",
      "Epoch 6/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3340.5233\n",
      "Epoch 7/30\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3337.5712\n",
      "Epoch 8/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3336.4414\n",
      "Epoch 9/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3334.8088\n",
      "Epoch 10/30\n",
      "322/322 [==============================] - 3s 9ms/sample - loss: 3331.2225\n",
      "Epoch 11/30\n",
      "322/322 [==============================] - 3s 9ms/sample - loss: 3331.2057\n",
      "Epoch 12/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3329.2621\n",
      "Epoch 13/30\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3324.9847\n",
      "Epoch 14/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3323.8937\n",
      "Epoch 15/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3320.6159\n",
      "Epoch 16/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3317.1727\n",
      "Epoch 17/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3315.6131\n",
      "Epoch 18/30\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3313.3822\n",
      "Epoch 19/30\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3309.8940\n",
      "Epoch 20/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3308.3957\n",
      "Epoch 21/30\n",
      "322/322 [==============================] - 3s 8ms/sample - loss: 3305.3622\n",
      "Epoch 22/30\n",
      "322/322 [==============================] - 3s 8ms/sample - loss: 3302.5956\n",
      "Epoch 23/30\n",
      "322/322 [==============================] - 2s 8ms/sample - loss: 3299.5474\n",
      "Epoch 24/30\n",
      "322/322 [==============================] - 2s 8ms/sample - loss: 3298.6199\n",
      "Epoch 25/30\n",
      "322/322 [==============================] - 3s 8ms/sample - loss: 3298.3625\n",
      "Epoch 26/30\n",
      "322/322 [==============================] - 3s 8ms/sample - loss: 3295.4925\n",
      "Epoch 27/30\n",
      "322/322 [==============================] - 3s 8ms/sample - loss: 3294.1932\n",
      "Epoch 28/30\n",
      "322/322 [==============================] - 2s 8ms/sample - loss: 3291.0745\n",
      "Epoch 29/30\n",
      "322/322 [==============================] - 3s 9ms/sample - loss: 3300.9546\n",
      "Epoch 30/30\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3290.9570\n",
      "Train on 322 samples, validate on 108 samples\n",
      "Epoch 1/1000\n",
      "322/322 [==============================] - 13s 40ms/sample - loss: 4490.9895 - val_loss: 4144.6165\n",
      "Epoch 2/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 4116.4825 - val_loss: 4044.9614\n",
      "Epoch 3/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3998.9634 - val_loss: 3960.9710\n",
      "Epoch 4/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3954.5646 - val_loss: 3940.8409\n",
      "Epoch 5/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3937.6241 - val_loss: 3939.9009\n",
      "Epoch 6/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3930.0369 - val_loss: 3933.5014\n",
      "Epoch 7/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3922.0812 - val_loss: 3914.9456\n",
      "Epoch 8/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3909.1606 - val_loss: 3919.2722\n",
      "Epoch 9/1000\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3912.6215 - val_loss: 3912.8139\n",
      "Epoch 10/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3901.2119 - val_loss: 3908.5746\n",
      "Epoch 11/1000\n",
      "322/322 [==============================] - 7s 22ms/sample - loss: 3896.6000 - val_loss: 3923.8217\n",
      "Epoch 12/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3907.6080 - val_loss: 3915.0790\n",
      "Epoch 13/1000\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3894.4023 - val_loss: 3916.2206\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 4s 13ms/sample - loss: 3893.8763 - val_loss: 3915.2019\n",
      "Epoch 15/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3891.5777 - val_loss: 3908.8019\n",
      "Epoch 16/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3885.7889 - val_loss: 3902.8400\n",
      "Epoch 17/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3880.4927 - val_loss: 3908.4260\n",
      "Epoch 18/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3887.7648 - val_loss: 3901.8986\n",
      "Epoch 19/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3880.8088 - val_loss: 3892.0816\n",
      "Epoch 20/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3880.2346 - val_loss: 3910.8499\n",
      "Epoch 21/1000\n",
      "322/322 [==============================] - 10s 30ms/sample - loss: 3882.3210 - val_loss: 3902.6800\n",
      "Epoch 22/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3874.4142 - val_loss: 3893.4479\n",
      "Epoch 23/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3872.1328 - val_loss: 3892.3591\n",
      "Epoch 24/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3864.8799 - val_loss: 3902.3306\n",
      "Epoch 25/1000\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3871.1318 - val_loss: 3893.0200\n",
      "Epoch 26/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3864.8982 - val_loss: 3900.0358\n",
      "Epoch 27/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3858.6579 - val_loss: 3891.6199\n",
      "Epoch 28/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3861.5467 - val_loss: 3897.4436\n",
      "Epoch 29/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3864.1143 - val_loss: 3892.6065\n",
      "Epoch 30/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3863.0642 - val_loss: 3893.1384\n",
      "Epoch 31/1000\n",
      "322/322 [==============================] - 7s 23ms/sample - loss: 3854.5463 - val_loss: 3911.0319\n",
      "Epoch 32/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3879.1934 - val_loss: 3892.3882\n",
      "Epoch 33/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3862.3738 - val_loss: 3890.8021\n",
      "Epoch 34/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3862.3941 - val_loss: 3890.2696\n",
      "Epoch 35/1000\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3856.2932 - val_loss: 3885.5185\n",
      "Epoch 36/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3853.2021 - val_loss: 3874.7523\n",
      "Epoch 37/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3856.5103 - val_loss: 3882.7284\n",
      "Epoch 38/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3856.7269 - val_loss: 3883.4903\n",
      "Epoch 39/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3850.6027 - val_loss: 3890.5169\n",
      "Epoch 40/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3850.8125 - val_loss: 3890.1366\n",
      "Epoch 41/1000\n",
      "322/322 [==============================] - 9s 27ms/sample - loss: 3846.2133 - val_loss: 3884.3333\n",
      "Epoch 42/1000\n",
      "322/322 [==============================] - 5s 15ms/sample - loss: 3851.9000 - val_loss: 3897.9396\n",
      "Epoch 43/1000\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3862.1378 - val_loss: 3879.4817\n",
      "Epoch 44/1000\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3846.4515 - val_loss: 3888.1079\n",
      "Epoch 45/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3853.0130 - val_loss: 3884.6204\n",
      "Epoch 46/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3840.9832 - val_loss: 3884.0735\n",
      "Epoch 47/1000\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3847.7557 - val_loss: 3887.2013\n",
      "Epoch 48/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3851.0370 - val_loss: 3882.3127\n",
      "Epoch 49/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3852.9206 - val_loss: 3885.8961\n",
      "Epoch 50/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3853.2167 - val_loss: 3887.1824\n",
      "Epoch 51/1000\n",
      "322/322 [==============================] - 8s 25ms/sample - loss: 3849.4764 - val_loss: 3879.2984\n",
      "Epoch 52/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3840.1568 - val_loss: 3876.8888\n",
      "Epoch 53/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3834.0758 - val_loss: 3888.7043\n",
      "Epoch 54/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3839.5267 - val_loss: 3882.8466\n",
      "Epoch 55/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3837.3124 - val_loss: 3865.7067\n",
      "Epoch 56/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3837.1523 - val_loss: 3886.8282\n",
      "Epoch 57/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3839.2716 - val_loss: 3878.7224\n",
      "Epoch 58/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3835.2181 - val_loss: 3885.8254\n",
      "Epoch 59/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3841.2622 - val_loss: 3881.2872\n",
      "Epoch 60/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3841.0012 - val_loss: 3874.5376\n",
      "Epoch 61/1000\n",
      "322/322 [==============================] - 8s 25ms/sample - loss: 3837.9435 - val_loss: 3875.6871\n",
      "Epoch 62/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3836.9687 - val_loss: 3876.5548\n",
      "Epoch 63/1000\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3841.1660 - val_loss: 3887.9271\n",
      "Epoch 64/1000\n",
      "322/322 [==============================] - 3s 10ms/sample - loss: 3833.6359 - val_loss: 3878.0195\n",
      "Epoch 65/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3836.3645 - val_loss: 3879.3599\n",
      "Epoch 66/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3833.9208 - val_loss: 3876.3540\n",
      "Epoch 67/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3837.3971 - val_loss: 3885.5420\n",
      "Epoch 68/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3834.6189 - val_loss: 3870.9498\n",
      "Epoch 69/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3828.5483 - val_loss: 3872.9747\n",
      "Epoch 70/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3824.9498 - val_loss: 3884.2306\n",
      "Epoch 71/1000\n",
      "322/322 [==============================] - 9s 29ms/sample - loss: 3827.7908 - val_loss: 3868.8439\n",
      "Epoch 72/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3827.0227 - val_loss: 3867.3942\n",
      "Epoch 73/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3820.3079 - val_loss: 3861.5945\n",
      "Epoch 74/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3829.9570 - val_loss: 3866.6434\n",
      "Epoch 75/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3827.0999 - val_loss: 3871.3482\n",
      "Epoch 76/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3828.5804 - val_loss: 3867.8165\n",
      "Epoch 77/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3819.7527 - val_loss: 3876.2962\n",
      "Epoch 78/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3818.7597 - val_loss: 3873.9629\n",
      "Epoch 79/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3827.2586 - val_loss: 3863.3843\n",
      "Epoch 80/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3821.2807 - val_loss: 3875.7309\n",
      "Epoch 81/1000\n",
      "322/322 [==============================] - 7s 22ms/sample - loss: 3818.6298 - val_loss: 3873.8168\n",
      "Epoch 82/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3820.3838 - val_loss: 3880.9869\n",
      "Epoch 83/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3823.0911 - val_loss: 3881.0630\n",
      "Epoch 84/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3823.7980 - val_loss: 3866.3473\n",
      "Epoch 85/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3819.2147 - val_loss: 3870.7027\n",
      "Epoch 86/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3813.1250 - val_loss: 3861.2394\n",
      "Epoch 87/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 5s 14ms/sample - loss: 3810.8829 - val_loss: 3874.5475\n",
      "Epoch 88/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3813.5717 - val_loss: 3879.8193\n",
      "Epoch 89/1000\n",
      "322/322 [==============================] - 5s 15ms/sample - loss: 3814.8933 - val_loss: 3872.6456\n",
      "Epoch 90/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3815.3954 - val_loss: 3876.1043\n",
      "Epoch 91/1000\n",
      "322/322 [==============================] - 9s 28ms/sample - loss: 3815.8603 - val_loss: 3865.9965\n",
      "Epoch 92/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3820.1224 - val_loss: 3871.3064\n",
      "Epoch 93/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3816.9590 - val_loss: 3858.2898\n",
      "Epoch 94/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3804.5641 - val_loss: 3856.7009\n",
      "Epoch 95/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3808.7212 - val_loss: 3861.9331\n",
      "Epoch 96/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3806.2875 - val_loss: 3857.9886\n",
      "Epoch 97/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3799.7611 - val_loss: 3861.6945\n",
      "Epoch 98/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3808.4347 - val_loss: 3872.5444\n",
      "Epoch 99/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3808.6061 - val_loss: 3872.8022\n",
      "Epoch 100/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3811.9687 - val_loss: 3860.6945\n",
      "Epoch 101/1000\n",
      "322/322 [==============================] - 8s 24ms/sample - loss: 3805.9220 - val_loss: 3853.0843\n",
      "Epoch 102/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3806.7051 - val_loss: 3862.4694\n",
      "Epoch 103/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3807.6268 - val_loss: 3870.0369\n",
      "Epoch 104/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3809.4304 - val_loss: 3875.2463\n",
      "Epoch 105/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3810.1320 - val_loss: 3865.8278\n",
      "Epoch 106/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3815.7374 - val_loss: 3874.9962\n",
      "Epoch 107/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3803.4707 - val_loss: 3869.8935\n",
      "Epoch 108/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3802.6143 - val_loss: 3856.0674\n",
      "Epoch 109/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3795.8975 - val_loss: 3855.2515\n",
      "Epoch 110/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3807.9493 - val_loss: 3856.2771\n",
      "Epoch 111/1000\n",
      "322/322 [==============================] - 9s 27ms/sample - loss: 3803.7155 - val_loss: 3858.7851\n",
      "Epoch 112/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3793.6585 - val_loss: 3855.0264\n",
      "Epoch 113/1000\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3789.0040 - val_loss: 3844.8951\n",
      "Epoch 114/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3797.2729 - val_loss: 3864.4878\n",
      "Epoch 115/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3796.9997 - val_loss: 3856.7396\n",
      "Epoch 116/1000\n",
      "322/322 [==============================] - 3s 11ms/sample - loss: 3794.6456 - val_loss: 3857.9426\n",
      "Epoch 117/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3796.0618 - val_loss: 3863.1369\n",
      "Epoch 118/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3791.0729 - val_loss: 3855.2548\n",
      "Epoch 119/1000\n",
      "322/322 [==============================] - 4s 12ms/sample - loss: 3789.5913 - val_loss: 3849.3498\n",
      "Epoch 120/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3788.0910 - val_loss: 3853.5258\n",
      "Epoch 121/1000\n",
      "322/322 [==============================] - 9s 29ms/sample - loss: 3787.7486 - val_loss: 3861.3215\n",
      "Epoch 122/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3782.9051 - val_loss: 3861.8249\n",
      "Epoch 123/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3786.7533 - val_loss: 3849.9461\n",
      "Epoch 124/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3786.8868 - val_loss: 3851.1974\n",
      "Epoch 125/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3788.7284 - val_loss: 3859.6784\n",
      "Epoch 126/1000\n",
      "322/322 [==============================] - 5s 14ms/sample - loss: 3786.8678 - val_loss: 3850.5122\n",
      "Epoch 127/1000\n",
      "322/322 [==============================] - 4s 14ms/sample - loss: 3781.8560 - val_loss: 3844.9944\n",
      "Epoch 128/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3782.0058 - val_loss: 3863.5892\n",
      "Epoch 129/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3796.4916 - val_loss: 3846.1318\n",
      "Epoch 130/1000\n",
      "322/322 [==============================] - 4s 13ms/sample - loss: 3786.2279 - val_loss: 3861.2621\n",
      "Epoch 131/1000\n",
      "322/322 [==============================] - 8s 24ms/sample - loss: 3781.1287 - val_loss: 3861.4809\n",
      "Epoch 132/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3788.1429 - val_loss: 3855.7200\n",
      "Epoch 133/1000\n",
      "322/322 [==============================] - 4s 11ms/sample - loss: 3782.4920 - val_loss: 3849.4101\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=20)\n",
    "plot_latent = PlotLatentSpace(model, X_train, y_train, interval=10)\n",
    "model.compile(optimizer=Adam(0.0001), loss=model.reconstruction_loss)\n",
    "history = model.fit(X_train, X_train, epochs=1000, validation_data=(X_test, X_test),\n",
    "                   callbacks=[early_stopping, plot_latent], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
